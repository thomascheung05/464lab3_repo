{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97c00b10-5edd-45d0-83ab-83693c41f056",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "The goal of this lab is to familiarize yourself with standard data wrangling tasks using Python. Being able to do so will greatly facilitate any work you do from here onward. After this lab, you should be comfortable enough in a Python data environment that we can begin using a variety of packages to analyze and visualize different kinds of data more freely."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703724bc-177c-4915-bc7e-e3e905d5c039",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Your second (and last) week as a data specialist at Via Rail\n",
    "\n",
    "Your supervisor at Via Rail has handed over more 'information'. This time, it's a few poorly formatted tables stored as *.txt* file. They want a basic map, and since Via is *finally* trying to enter the digital age with all this new federal funding, they want this map to create itself with the click of a button (in this case, by running all code cells in this notebook). Like last week, you assume there will be more data coming your way in this format, so you will need to come up with an automated process that imports it, parses it, and does any subesquent operations that are necessary in order to finally prep it for the mapping intern. In other words, you need to write a program that takes data of a certain format as input, and generates clean data as an output."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3afb7b-6828-495e-acb9-68d98fd16659",
   "metadata": {},
   "source": [
    "## Importing packages\n",
    "\n",
    "At the start of any Python script (or Jupyter notebook running Python) you will usually want to import packages so that their functionality is available to the rest of your code. One of Python's great strengths is the quality of its 3rd party packages, which can provide functionality for doing anything from video editing to running a web server to... managing data! In this session, we would like to import the [Pandas](https://pandas.pydata.org/) package. Pandas allows us to manipulate data stored in Pandas dataframes, and forms the bedrock of most standard data analysis done with Python today. Familiarity with other basic data management software (e.g. Excel) will serve you well here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "4b2f5984-e861-4381-b6dc-60b3e20ef2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the below command imports pandas\n",
    "import pandas\n",
    "\n",
    "#when importing a package, you can give it the alias of your choice by appending 'as' followed by your alias.\n",
    "#doing so can make it more practical for you to refer to the package in your code, especially if the package were to have a really long name...\n",
    "import pandas as pd\n",
    "\n",
    "#from here on, we can refer to pandas simply as 'pd'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01bf32a8-5361-4d65-ba3c-312e74424cff",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Inspecting and importing data\n",
    "\n",
    "Make sure you *know* your data. The first thing you should always do before importing data is to inspect it.\n",
    "- From your command line or file explorer (Windows Explorer/Finder), open *stations.txt* in a text editor (Notepad/Text Edit)\n",
    "\n",
    "What do you observe? Look for patterns in the data: can you spot any characteristics that you could use to parse it into a table? Ideally, you would like to convert this into a clean table where each data point is separated into its own cell under a header. If you are good in Excel, you could easily clean this up in that software. However, you want your process to be as automated as possible, so your initial script will involve some of what you did last week.\n",
    "\n",
    "1. What would you say is the 'delimiter' or 'separator' for this data? Doesthe data have headers? Indicate your answers in a Markdown cell below."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5ec7c02b-f5ce-455c-9324-4b86c9bc206f",
   "metadata": {},
   "source": [
    "Each entry is delimited with semi-colons (;), which would correspond to different variables separated into columns in a dataframe. However, these variables/columns do not have names/headers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c2540b-16b8-4827-b3f6-650a418229f2",
   "metadata": {},
   "source": [
    "- close the file *stations.txt*.\n",
    "\n",
    "Now you're going to import this dataset. Pandas has a method called [*read_csv*](https://Pandas.pydata.org/docs/user_guide/io.html#csv-text-files), which can be used to import almost any kind of table into a [Pandas dataframe](https://pandas.pydata.org/docs/user_guide/dsintro.html#dataframe). Although your data doesn't have headers, there is a file in this lab which lists these...\n",
    "\n",
    "The *read_csv* Pandas method can take a series of optional parameters, which we call 'arguments' and 'keyword arguments' respectively. **To continue, you will need to indicate a value for each of the two following variables.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "28892151-63bf-4d85-8435-22b595770b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we will begin by filling a pathname so the read_csv method can find the stations.txt file\n",
    "#you may need to modify this pathname to reflect the location of the stations.txt file on your computer\n",
    "path_stations = \"Lab 3 Data Wrangling Stations.txt\"\n",
    "\n",
    "#a string (my_sep) will be passed to the 'sep' argument of the read_csv method\n",
    "#and the other, a list of strings (my_headers), will be used by the 'names' argument. You can find these headers in headers.txt\n",
    "my_sep = \";\"\n",
    "my_headers = \"object_ID;stat_num;stat_ID;stat_name;street_num;street;address_2;city;province;postal_code;country\" #copy this in from the headers.txt file\n",
    "my_headers = my_headers.split(my_sep)\n",
    "\n",
    "df_stations = pd.read_csv(path_stations, sep = my_sep, header = None, names = my_headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75fd5276-7ccf-4153-9bcc-29e8c21079da",
   "metadata": {},
   "source": [
    "Yay! Now you can start working with Pandas.\n",
    "\n",
    "You now have a Pandas dataframe stored in a variable called *df_stations*.\n",
    "The print statement can be used to display the dataframe once imported, but Jupyter is able to render dataframes in a more appealing way. Find active variables in the side panes of Google Colab, or, in VS Code, under the 'Jupyter' tab of the bottom tray (beside the terminal)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "e46afbbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     object_ID  stat_num stat_ID                                 stat_name  \\\n",
      "0            1       555    XYUL  Aeroport Montreal Pierre-Elliott Trudeau   \n",
      "1            2       600    ALDR                                 Aldershot   \n",
      "2            3       344    ALEX                                Alexandria   \n",
      "3            4       221    AMQU                                     Amqui   \n",
      "4            5       636    AMYO                                     Amyot   \n",
      "..         ...       ...     ...                                       ...   \n",
      "204        205       299    WNDG                                   Windigo   \n",
      "205        206       618    WDON                                   Windsor   \n",
      "206        207       128    WOMR                               Woman River   \n",
      "207        208       282    WDST                                 Woodstock   \n",
      "208        209       280    WYOM                                   Wyoming   \n",
      "\n",
      "     street_num                                 street  address_2  \\\n",
      "0           NaN  Boulevard Roméo-Vachon Nord (départs)        NaN   \n",
      "1           NaN                            East Tunnel        NaN   \n",
      "2          45.0                  McDougald Street East        NaN   \n",
      "3           NaN           Boulevard Saint-Benoît Ouest        NaN   \n",
      "4           NaN                            Road 8 & 20        NaN   \n",
      "..          ...                                    ...        ...   \n",
      "204         NaN                               Route 11        NaN   \n",
      "205         NaN                       Montreuil Avenue        NaN   \n",
      "206         NaN                         Hong Kong Road        NaN   \n",
      "207       100.0                  Victoria Street South        NaN   \n",
      "208       579.0                           Front Street        NaN   \n",
      "\n",
      "                          city province postal_code country  \n",
      "0                          NaN   Quebec     H4Y 0A4  Canada  \n",
      "1                   Burlington  Ontario     L7T 2C4  Canada  \n",
      "2              North Glengarry  Ontario     K0C 1A0  Canada  \n",
      "3                          NaN   Quebec     G5J 2E8  Canada  \n",
      "4     Unorganized North Algoma  Ontario         NaN  Canada  \n",
      "..                         ...      ...         ...     ...  \n",
      "204                        NaN   Quebec     G9X 3P4  Canada  \n",
      "205                    Windsor  Ontario     N8Y 2M9  Canada  \n",
      "206  Unorganized North Sudbury  Ontario         NaN  Canada  \n",
      "207                  Woodstock  Ontario     N4S 8R4  Canada  \n",
      "208                        NaN  Ontario     N0N 1T0  Canada  \n",
      "\n",
      "[209 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_stations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52519a0-f594-4eed-b9db-4e4503177aca",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Exploring Pandas dataframes\n",
    "\n",
    "You can see that not all your data is visible. It would take up a lot of space to display all your data like an Excel sheet (besides, you have other software for doing that). You can use the following dataframe methods to explore your data in Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "9f16724b-e961-41a3-9bae-7db943be764d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>object_ID</th>\n",
       "      <th>stat_num</th>\n",
       "      <th>stat_ID</th>\n",
       "      <th>stat_name</th>\n",
       "      <th>street_num</th>\n",
       "      <th>street</th>\n",
       "      <th>address_2</th>\n",
       "      <th>city</th>\n",
       "      <th>province</th>\n",
       "      <th>postal_code</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>555</td>\n",
       "      <td>XYUL</td>\n",
       "      <td>Aeroport Montreal Pierre-Elliott Trudeau</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Boulevard Roméo-Vachon Nord (départs)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Quebec</td>\n",
       "      <td>H4Y 0A4</td>\n",
       "      <td>Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>600</td>\n",
       "      <td>ALDR</td>\n",
       "      <td>Aldershot</td>\n",
       "      <td>NaN</td>\n",
       "      <td>East Tunnel</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Burlington</td>\n",
       "      <td>Ontario</td>\n",
       "      <td>L7T 2C4</td>\n",
       "      <td>Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>344</td>\n",
       "      <td>ALEX</td>\n",
       "      <td>Alexandria</td>\n",
       "      <td>45.0</td>\n",
       "      <td>McDougald Street East</td>\n",
       "      <td>NaN</td>\n",
       "      <td>North Glengarry</td>\n",
       "      <td>Ontario</td>\n",
       "      <td>K0C 1A0</td>\n",
       "      <td>Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>221</td>\n",
       "      <td>AMQU</td>\n",
       "      <td>Amqui</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Boulevard Saint-Benoît Ouest</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Quebec</td>\n",
       "      <td>G5J 2E8</td>\n",
       "      <td>Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>636</td>\n",
       "      <td>AMYO</td>\n",
       "      <td>Amyot</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Road 8 &amp; 20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unorganized North Algoma</td>\n",
       "      <td>Ontario</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Canada</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   object_ID  stat_num stat_ID                                 stat_name  \\\n",
       "0          1       555    XYUL  Aeroport Montreal Pierre-Elliott Trudeau   \n",
       "1          2       600    ALDR                                 Aldershot   \n",
       "2          3       344    ALEX                                Alexandria   \n",
       "3          4       221    AMQU                                     Amqui   \n",
       "4          5       636    AMYO                                     Amyot   \n",
       "\n",
       "   street_num                                 street  address_2  \\\n",
       "0         NaN  Boulevard Roméo-Vachon Nord (départs)        NaN   \n",
       "1         NaN                            East Tunnel        NaN   \n",
       "2        45.0                  McDougald Street East        NaN   \n",
       "3         NaN           Boulevard Saint-Benoît Ouest        NaN   \n",
       "4         NaN                            Road 8 & 20        NaN   \n",
       "\n",
       "                       city province postal_code country  \n",
       "0                       NaN   Quebec     H4Y 0A4  Canada  \n",
       "1                Burlington  Ontario     L7T 2C4  Canada  \n",
       "2           North Glengarry  Ontario     K0C 1A0  Canada  \n",
       "3                       NaN   Quebec     G5J 2E8  Canada  \n",
       "4  Unorganized North Algoma  Ontario         NaN  Canada  "
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#head will show you the top 5 rows\n",
    "df_stations.head()\n",
    "\n",
    "#you can also add a number indicating how many rows you would like to see inside the parentheses ()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca89798-d423-461c-9279-cf530cde5b68",
   "metadata": {},
   "source": [
    "You can also use the tail method to show the last rows of a dataframe.\n",
    "\n",
    "2. Use the tail method with the appropriate argument in the code cell below to show the last 15 rows of *stations_df*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "cd82f4b7-d01b-434d-9c9c-54a9d4c1f8a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     object_ID  stat_num stat_ID         stat_name  street_num  \\\n",
      "194        195       119    TRTO           Toronto       140.0   \n",
      "195        196       413    TRNJ  Trenton Junction         NaN   \n",
      "196        197       170    TPIS    Trois Pistoles         NaN   \n",
      "197        198       247    VBRU     Van Bruyssels         NaN   \n",
      "198        199       339    VDRY            Vandry         NaN   \n",
      "199        200        59    WSHG           Washago         NaN   \n",
      "200        201        76    WSTR           Westree         NaN   \n",
      "201        202        49    WYMT           Weymont         NaN   \n",
      "202        203       116    WHTR       White River         NaN   \n",
      "203        204       168    WGWC            Wigwam         NaN   \n",
      "204        205       299    WNDG           Windigo         NaN   \n",
      "205        206       618    WDON           Windsor         NaN   \n",
      "206        207       128    WOMR       Woman River         NaN   \n",
      "207        208       282    WDST         Woodstock       100.0   \n",
      "208        209       280    WYOM           Wyoming       579.0   \n",
      "\n",
      "                             street  address_2                       city  \\\n",
      "194                      Bay Street        NaN                    Toronto   \n",
      "195                  Telephone Road        NaN                Quinte West   \n",
      "196                  Rue de la Gare        NaN                        NaN   \n",
      "197  Chemin Van Bruyssel-Kiskissink        NaN                        NaN   \n",
      "198                Chemin de Vandry        NaN                        NaN   \n",
      "199                  Quetton Street        NaN                     Severn   \n",
      "200                             NaN        NaN  Unorganized North Sudbury   \n",
      "201                           Rue A        NaN                        NaN   \n",
      "202           Winnipeg Street North        NaN                        NaN   \n",
      "203                             NaN        NaN                        NaN   \n",
      "204                        Route 11        NaN                        NaN   \n",
      "205                Montreuil Avenue        NaN                    Windsor   \n",
      "206                  Hong Kong Road        NaN  Unorganized North Sudbury   \n",
      "207           Victoria Street South        NaN                  Woodstock   \n",
      "208                    Front Street        NaN                        NaN   \n",
      "\n",
      "    province postal_code country  \n",
      "194  Ontario     M5J 2L5  Canada  \n",
      "195  Ontario     K8V 5P9  Canada  \n",
      "196   Quebec     G0L 4K0  Canada  \n",
      "197   Quebec         NaN  Canada  \n",
      "198   Quebec         NaN  Canada  \n",
      "199  Ontario     L0K 2B0  Canada  \n",
      "200  Ontario         NaN  Canada  \n",
      "201   Quebec     G0X 3R0  Canada  \n",
      "202  Ontario         NaN  Canada  \n",
      "203   Quebec         NaN  Canada  \n",
      "204   Quebec     G9X 3P4  Canada  \n",
      "205  Ontario     N8Y 2M9  Canada  \n",
      "206  Ontario         NaN  Canada  \n",
      "207  Ontario     N4S 8R4  Canada  \n",
      "208  Ontario     N0N 1T0  Canada  \n"
     ]
    }
   ],
   "source": [
    "print(df_stations.tail(15))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98aba72-cec4-4deb-a2e8-b762f59c0823",
   "metadata": {},
   "source": [
    "Below are some other commands you can use to explore your data..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "c48043d8-e29b-424b-bf01-058764e80ea2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(209, 11)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#shape will return a tuple containing the number of rows followed by the number of columns.\n",
    "df_stations.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "78c13679-494c-46cc-b1b6-b769792d3c5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 209 entries, 0 to 208\n",
      "Data columns (total 11 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   object_ID    209 non-null    int64  \n",
      " 1   stat_num     209 non-null    int64  \n",
      " 2   stat_ID      209 non-null    object \n",
      " 3   stat_name    209 non-null    object \n",
      " 4   street_num   28 non-null     float64\n",
      " 5   street       161 non-null    object \n",
      " 6   address_2    0 non-null      float64\n",
      " 7   city         100 non-null    object \n",
      " 8   province     209 non-null    object \n",
      " 9   postal_code  99 non-null     object \n",
      " 10  country      209 non-null    object \n",
      "dtypes: float64(2), int64(2), object(7)\n",
      "memory usage: 18.1+ KB\n"
     ]
    }
   ],
   "source": [
    "#info will show you useful information related to your data\n",
    "df_stations.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "d02491fa-6950-433f-a237-1f0c74d27ec9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>object_ID</th>\n",
       "      <th>stat_num</th>\n",
       "      <th>street_num</th>\n",
       "      <th>address_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>209.000000</td>\n",
       "      <td>209.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>105.000000</td>\n",
       "      <td>250.488038</td>\n",
       "      <td>382.964286</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>60.477268</td>\n",
       "      <td>176.179190</td>\n",
       "      <td>738.454215</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>53.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>48.750000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>105.000000</td>\n",
       "      <td>217.000000</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>157.000000</td>\n",
       "      <td>390.000000</td>\n",
       "      <td>365.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>209.000000</td>\n",
       "      <td>639.000000</td>\n",
       "      <td>3875.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        object_ID    stat_num   street_num  address_2\n",
       "count  209.000000  209.000000    28.000000        0.0\n",
       "mean   105.000000  250.488038   382.964286        NaN\n",
       "std     60.477268  176.179190   738.454215        NaN\n",
       "min      1.000000    1.000000     1.000000        NaN\n",
       "25%     53.000000   95.000000    48.750000        NaN\n",
       "50%    105.000000  217.000000   166.000000        NaN\n",
       "75%    157.000000  390.000000   365.000000        NaN\n",
       "max    209.000000  639.000000  3875.000000        NaN"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#describe will compute some summary statistics about your data\n",
    "#note that such statistics may be meaningless depending on the nature of your data\n",
    "df_stations.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1cf0489-56a9-4f67-bc17-4a3233f2bccf",
   "metadata": {},
   "source": [
    "3. Based on the information provided by the commands above, how many stations are there in your data?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "885f4991-40d4-4b1f-b312-3fbdf1d16db9",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "63aa8078-0289-45ce-b9b5-ca33e96e83c9",
   "metadata": {},
   "source": [
    "4. Based on the information provided by the commands above, how many different cities are represented in your data? You may wish to run another command to better elucidate this info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "ebd3c035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(209, 11)\n"
     ]
    }
   ],
   "source": [
    "print(df_stations.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1e5cc00b",
   "metadata": {},
   "source": [
    "From the shape function we can see there are 209 stations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d94f6470-acc8-4ae1-b6fd-00f6d583db7f",
   "metadata": {},
   "source": [
    "5. Why do you think the *describe()* method is only providing summary stats for a limited number of fields?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "de4ea326-cd5d-4a2d-9684-888e25529850",
   "metadata": {},
   "source": [
    "The describe fuction produces statistical stats of each column. It can only describe columns that have numeric values as you cannot find the mean of a column full of strings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71463b21-d9d3-4275-9328-a4e8b7fc009a",
   "metadata": {},
   "source": [
    "You can easily create new dataframes by subsetting; or, in other words, selecting specific columns to assign to a new dataframe. This is great for shedding columns you might not need. Subsetting a dataframe has similarities to how you would do it with a dictionary: You use the [] to select fields by their header names. See below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "c7443515-cd86-4d82-82fb-3d3c75113ed6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#to isolate a single column, simply select the header like you would a key in a dictionary.\n",
    "#This creates a Pandas 'series', which is kind of analogous to a list. It's basically a one-dimensional dataframe...\n",
    "station_names = df_stations['stat_name']\n",
    "station_names.head()\n",
    "\n",
    "#pass station_names to the type() function. What data type is it?\n",
    "type(station_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "cad745d7-ba12-45e0-b8ad-8fe6bd31cce3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stat_ID</th>\n",
       "      <th>stat_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XYUL</td>\n",
       "      <td>Aeroport Montreal Pierre-Elliott Trudeau</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ALDR</td>\n",
       "      <td>Aldershot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ALEX</td>\n",
       "      <td>Alexandria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AMQU</td>\n",
       "      <td>Amqui</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AMYO</td>\n",
       "      <td>Amyot</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  stat_ID                                 stat_name\n",
       "0    XYUL  Aeroport Montreal Pierre-Elliott Trudeau\n",
       "1    ALDR                                 Aldershot\n",
       "2    ALEX                                Alexandria\n",
       "3    AMQU                                     Amqui\n",
       "4    AMYO                                     Amyot"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#for example, let's create a new dataframe that only contains the station ID and station name.\n",
    "#to subset multiple columns to a new dataframe, you will need to pass a list of these headers\n",
    "little_df = df_stations[['stat_ID','stat_name']]\n",
    "little_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2e97ed-720b-43d6-b977-933657bc33fc",
   "metadata": {},
   "source": [
    "6. In the code cell below, create a new dataframe called *temp_df* that only contains the following fields: *stat_ID*, *stat_name*, *city*, *postal_code*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "5131c9e2-da21-4ad6-9e72-51230457902c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  stat_ID                                 stat_name                      city  \\\n",
      "0    XYUL  Aeroport Montreal Pierre-Elliott Trudeau                       NaN   \n",
      "1    ALDR                                 Aldershot                Burlington   \n",
      "2    ALEX                                Alexandria           North Glengarry   \n",
      "3    AMQU                                     Amqui                       NaN   \n",
      "4    AMYO                                     Amyot  Unorganized North Algoma   \n",
      "\n",
      "  postal_code  \n",
      "0     H4Y 0A4  \n",
      "1     L7T 2C4  \n",
      "2     K0C 1A0  \n",
      "3     G5J 2E8  \n",
      "4         NaN  \n"
     ]
    }
   ],
   "source": [
    "temp_df = df_stations[[\"stat_ID\", \"stat_name\", \"city\", \"postal_code\"]]\n",
    "\n",
    "print(temp_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f891c3a-a1c9-42e5-9c33-6bc2ff3c6435",
   "metadata": {},
   "source": [
    "Another way of shedding unneeded columns is simply to delete them in-place (within the original dataframe). In *df_stations*, There are columns which you could do without. These would be the following: *object_ID*, *address_2*\n",
    "\n",
    "These two fields are by most measures useless. You can tell because they are either zombie ID fields, or contain so few values that their use in any scenario is questionable. Search for the delete method in the [Pandas documentation](https://pandas.pydata.org/docs/user_guide/index.html) and delete these fields!\n",
    "\n",
    "(hint: you might want to check inside the page on dataframes...)\n",
    "\n",
    "Once you find the relevant information, you will see that there are two common ways of deleting fields: 'del', and the more familiar 'pop' method used with lists.\n",
    "\n",
    "7. Use the pop method to delete these fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "a094b3d4-4468-4f91-9940-60a9797820d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     stat_num stat_ID                                 stat_name  street_num  \\\n",
      "0         555    XYUL  Aeroport Montreal Pierre-Elliott Trudeau         NaN   \n",
      "1         600    ALDR                                 Aldershot         NaN   \n",
      "2         344    ALEX                                Alexandria        45.0   \n",
      "3         221    AMQU                                     Amqui         NaN   \n",
      "4         636    AMYO                                     Amyot         NaN   \n",
      "..        ...     ...                                       ...         ...   \n",
      "204       299    WNDG                                   Windigo         NaN   \n",
      "205       618    WDON                                   Windsor         NaN   \n",
      "206       128    WOMR                               Woman River         NaN   \n",
      "207       282    WDST                                 Woodstock       100.0   \n",
      "208       280    WYOM                                   Wyoming       579.0   \n",
      "\n",
      "                                    street                       city  \\\n",
      "0    Boulevard Roméo-Vachon Nord (départs)                        NaN   \n",
      "1                              East Tunnel                 Burlington   \n",
      "2                    McDougald Street East            North Glengarry   \n",
      "3             Boulevard Saint-Benoît Ouest                        NaN   \n",
      "4                              Road 8 & 20   Unorganized North Algoma   \n",
      "..                                     ...                        ...   \n",
      "204                               Route 11                        NaN   \n",
      "205                       Montreuil Avenue                    Windsor   \n",
      "206                         Hong Kong Road  Unorganized North Sudbury   \n",
      "207                  Victoria Street South                  Woodstock   \n",
      "208                           Front Street                        NaN   \n",
      "\n",
      "    province postal_code country  \n",
      "0     Quebec     H4Y 0A4  Canada  \n",
      "1    Ontario     L7T 2C4  Canada  \n",
      "2    Ontario     K0C 1A0  Canada  \n",
      "3     Quebec     G5J 2E8  Canada  \n",
      "4    Ontario         NaN  Canada  \n",
      "..       ...         ...     ...  \n",
      "204   Quebec     G9X 3P4  Canada  \n",
      "205  Ontario     N8Y 2M9  Canada  \n",
      "206  Ontario         NaN  Canada  \n",
      "207  Ontario     N4S 8R4  Canada  \n",
      "208  Ontario     N0N 1T0  Canada  \n",
      "\n",
      "[209 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "#use the pop method\n",
    "\n",
    "\n",
    "df_addy = df_stations.pop('address_2')\n",
    "df_obj = df_stations.pop('object_ID')\n",
    "\n",
    "\n",
    "\n",
    "# # #then run the cell to display your dataframe below and make sure everything is as expected\n",
    "# df_stations.head()\n",
    "print(df_stations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b40ace-13db-460b-8760-61addac8848b",
   "metadata": {},
   "source": [
    "8. Once you have run your deletions in the cell above, run the code cell again. Why does it fail? What is a KeyError?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1eaec642-6d24-4da7-9873-c3e8a682d1e6",
   "metadata": {},
   "source": [
    "It fails becuase we have already deleted the columns. So when we go back to delete it again the computer cant find the columns (they've already been deleted) giving us a key error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e98229-2a2e-48fa-b117-4af6e63d5096",
   "metadata": {},
   "source": [
    "## Preparing your data for the mapping intern\n",
    "\n",
    "Now that your table is all cleaned up, it's time to prepare it for mapping. There's one issue though: the data you've been working with so far doesn't seem to have any explicit location information (i.e. coordinates). There is other geographic information in your table, however, which you could potentially exploit for mapping purposes. Can you name which fields these would be?\n",
    "\n",
    "9. Which fields do you think you would need in order to [geocode](https://desktop.arcgis.com/en/arcmap/latest/manage-data/geocoding/what-is-geocoding.htm) these transit stations? Name all that apply in the Markdown cell below."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "42e4bcdc-4784-4b40-b912-3b86ee3e8cf8",
   "metadata": {},
   "source": [
    "You could use the street name in combination with the street number although these fields are missing in some of the rows. You could also use postal code or most likely a combination of all 3."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5c790d-1525-4f04-b00d-dc5563354dd9",
   "metadata": {
    "tags": []
   },
   "source": [
    "Luckily, you won't need to be doing any geocoding today, since you noticed that your supervisor also left you with another file called *coordinates.txt*.\n",
    "\n",
    "10. Open the file in a text editor and inspect it like you did with the stations file. Do you notice a pattern here which you could use for parsing the data?\n",
    "- What would the delimiter be for this data? What file extension do we typically use to associate to this delimiter?\n",
    "- Does the data have headers?\n",
    "- Can you identify a field in *coordinates.txt* that you could use to merge with your stations data? Which field?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "557e6cb6-8f21-4abb-bb92-717f4cd5de38",
   "metadata": {},
   "source": [
    "The delimeters are ',' and normally this file extension would be '.csv'. Yes the data does have headers: lat,lon,stat_ID. We could use the stat_ID to merge the two datasets.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c31652-d24f-4ca1-91ed-85de1313076d",
   "metadata": {},
   "source": [
    "11. Import *coords.txt* into JupyterLab using the appropriate Pandas method (you've done this before!) and assign the dataframe to a variable called *df_coords*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "e2038585-c2ee-43af-ae83-a4d0c30ccea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           lat        lon stat_ID\n",
      "0    45.456988 -73.751834    XYUL\n",
      "1    43.312886 -79.855009    ALDR\n",
      "2    45.318050 -74.639672    ALEX\n",
      "3    48.466260 -67.436172    AMQU\n",
      "4    48.482877 -84.954122    AMYO\n",
      "..         ...        ...     ...\n",
      "204  47.771220 -73.334097    WNDG\n",
      "205  42.324933 -83.007134    WDON\n",
      "206  47.511624 -82.628067    WOMR\n",
      "207  43.126528 -80.752123    WDST\n",
      "208  42.947960 -82.122260    WYOM\n",
      "\n",
      "[209 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "path_coords = \"Lab 3 Coordinates.txt\"\n",
    "\n",
    "df_coords = pd.read_csv(path_coords)\n",
    "print(df_coords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dffa57a-831c-43c8-8288-b18657d25127",
   "metadata": {},
   "source": [
    "## Merging dataframes\n",
    "\n",
    "You will need to join your coordinate data with your station information. You can do this using the Pandas [merge method](https://pandas.pydata.org/docs/user_guide/merging.html#database-style-dataframe-or-named-series-joining-merging)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92234679-2e73-46f4-bc48-dc804bc4f41f",
   "metadata": {},
   "source": [
    "Before doing a merge, you should identify which column can be used to perform the merge. [Merges](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.merge.html) are very similar to standard [join operations](https://dataschool.com/assets/images/how-to-teach-people-sql/sqlJoins/sqlJoins_7.png) in SQL, which you have probably seen in software like ArcGIS before (e.g. joining some data to the attribute table of a shapefile based on a common identifier).\n",
    "\n",
    "To merge tables, you will need to identify a column that contains values which can be used to match rows from each table to eachother.\n",
    "\n",
    "**Take note of which column you could use as a join field for merging *df_stations* with *df_coords*.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139a7d09-9f4b-42f3-8480-18f39829a668",
   "metadata": {},
   "source": [
    "Before performing a merge, you want to make sure there are no duplicates in your data. A duplicate could mean that the same row from the table being merged gets joined twice or more. The [duplicated method](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.duplicated.html) can serve you well here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "b2834276-f8bf-4b75-abde-5660f3062bf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "duplicates = df_coords.duplicated()\n",
    "print(type(duplicates))\n",
    "#below is a little loop for verifying if there are any duplicates (note that there are simpler ways of doing this with Pandas than using a for loop)\n",
    "for x in duplicates:\n",
    "    if x == True:\n",
    "        print(x)\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d07e5fe0-93cc-46ac-8093-366ab3d6957f",
   "metadata": {},
   "source": [
    "12. What data type is being generated by the duplicated() method? Are there any duplicates in *df_stations*? Run a code cell to determine this, then a short text explanation in a Markdown cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "85c2809e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are no duplicate rows!!\n"
     ]
    }
   ],
   "source": [
    "if duplicates.any(): # I used Ai to find the .any fuction, i tried to use \"if True in duplicates\" but that didnt work with the list so i needed to find another way \n",
    "    print(\"There are duplicate rows\")\n",
    "else:\n",
    "    print(\"There are no duplicate rows!!\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cb2034db-b8e7-4074-9c91-0b060aadb669",
   "metadata": {},
   "source": [
    "The duplicates method is generating a pandas series of boolean true of false values, if a row has a duplicate its cooreponding position in the duplicates series would display true. There are no duplicates. In the code block above, I am checking if \"True\" is wihtin the entire list. If yes this means there is at least 1 duplicate row, if no this means all the values are false and there are no duplicates. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c632597-1106-4e5a-b570-f159d70ac6e2",
   "metadata": {},
   "source": [
    "The code below will test whether there are any duplicates specifically within the *stat_ID* field, which could be a good field for eventually merging the data..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "2966487d-9c87-434e-9c62-68128a62ad28",
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicates = df_stations['stat_ID'].duplicated()\n",
    "\n",
    "for x in duplicates:\n",
    "    if x == True:\n",
    "        print(x)\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cafb2e46-d91c-4d02-98e4-cc845c51d748",
   "metadata": {},
   "source": [
    "### Using a custom function to check for duplicates\n",
    "\n",
    "[Functions](https://www.w3schools.com/python/python_functions.asp) are a great way to organize your code. Basically, you can wrap any code inside a function, which allows you to call that code from anywhere else in your code without having to rewrite the code all over again! Think of it as a more elaborate variable, but a variable that *does* stuff, instead of just holding static information. Like variables, you need to declare a function first before using it. After that, you can refer to it anywhere, as long as you pass it the right arguments!\n",
    "\n",
    "Functions in Python are declared using the 'def' keyword. Immediately following the name of the function - which is up to you to choose - and much like any variable name, you need to add parentheses (()). Inside these parentheses is where you can pass arguments to the function (i.e. input data).\n",
    "\n",
    "Like conditional statements or loops, function declarations are immediately followed by a colon (:), and any code nested inside a function is indented. The 'return' statement at the end of a function signals what it will output. Think of the () of the function as the point of entry, and the 'return' statement as the exit.\n",
    "\n",
    "13. You would like to write a custom function to check for duplicates so that you can freely call it from anywhere in your code. Your function should require a **list of booleans as input**, and **return a number indicating the number of duplicates** (i.e. True values) in the list that was passed to it. Use the documentation provided above to familiarize yourself with functions (and any other documentation you can find).\n",
    "\n",
    "Hint: len() will provide the length of a list (and therefore a number). .append() can be used for appending True values to a list, which you can then use len() on as your return value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "20115843-7967-4c31-8c80-cb8de92b5053",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dup(duplicates_list):\n",
    "    if duplicates_list.any():\n",
    "        print(\"There are duplicates: \")\n",
    "        num_trues = 0\n",
    "        for x in duplicates_list:\n",
    "            if x == True:\n",
    "                num_trues = num_trues + 1\n",
    "            else:\n",
    "                pass\n",
    "        print(\"There are\", num_trues, \"duplicate rows\")\n",
    "    else:\n",
    "        print(\"There are no duplicate rows!!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b974ea80-d26a-47f5-a6aa-438d1a08e79e",
   "metadata": {},
   "source": [
    "14. How many duplicates are there in the *city* field of df_stations? Produce the result in the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "0eb2c799-4ea5-41b3-a663-65221d3807b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are duplicates: \n",
      "There are 163 duplicate rows\n"
     ]
    }
   ],
   "source": [
    "city_dups = df_stations['city'].duplicated()\n",
    "\n",
    "dup(city_dups)\n",
    "\n",
    "# df_stations.to_csv('df_stations.csv',header=True,index=True)\n",
    "# city_dups.to_csv('city_dups.csv',header=True,index=True)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc074f5-4d56-4148-804c-8c111aadb8f1",
   "metadata": {},
   "source": [
    "### Merging at last!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496a3a32-ab95-4e74-a10b-f52d91697937",
   "metadata": {},
   "source": [
    "Now that you are certain there are no duplicates, you can feel confident about merging these tables. \n",
    "\n",
    "15. Finally, use the documentation (links) provided above (under the **Merging dataframes** title) to perform this merge. You can also use Google or ask an AI chatbot if you need other resources. You will need to do your own research here. However, the task shouldn't be too complex, and you shouldn't have to use too many of the optional parameters (keyword arguments) that the merge method provides. Assign your merged data to a dataframe called *df_stations_coords*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "3c199556-fe55-465a-86d3-91b52125d89d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     stat_num stat_ID                                 stat_name  street_num  \\\n",
      "0         555    XYUL  Aeroport Montreal Pierre-Elliott Trudeau         NaN   \n",
      "1         600    ALDR                                 Aldershot         NaN   \n",
      "2         344    ALEX                                Alexandria        45.0   \n",
      "3         221    AMQU                                     Amqui         NaN   \n",
      "4         636    AMYO                                     Amyot         NaN   \n",
      "..        ...     ...                                       ...         ...   \n",
      "204       299    WNDG                                   Windigo         NaN   \n",
      "205       618    WDON                                   Windsor         NaN   \n",
      "206       128    WOMR                               Woman River         NaN   \n",
      "207       282    WDST                                 Woodstock       100.0   \n",
      "208       280    WYOM                                   Wyoming       579.0   \n",
      "\n",
      "                                    street                       city  \\\n",
      "0    Boulevard Roméo-Vachon Nord (départs)                        NaN   \n",
      "1                              East Tunnel                 Burlington   \n",
      "2                    McDougald Street East            North Glengarry   \n",
      "3             Boulevard Saint-Benoît Ouest                        NaN   \n",
      "4                              Road 8 & 20   Unorganized North Algoma   \n",
      "..                                     ...                        ...   \n",
      "204                               Route 11                        NaN   \n",
      "205                       Montreuil Avenue                    Windsor   \n",
      "206                         Hong Kong Road  Unorganized North Sudbury   \n",
      "207                  Victoria Street South                  Woodstock   \n",
      "208                           Front Street                        NaN   \n",
      "\n",
      "    province postal_code country        lat        lon  \n",
      "0     Quebec     H4Y 0A4  Canada  45.456988 -73.751834  \n",
      "1    Ontario     L7T 2C4  Canada  43.312886 -79.855009  \n",
      "2    Ontario     K0C 1A0  Canada  45.318050 -74.639672  \n",
      "3     Quebec     G5J 2E8  Canada  48.466260 -67.436172  \n",
      "4    Ontario         NaN  Canada  48.482877 -84.954122  \n",
      "..       ...         ...     ...        ...        ...  \n",
      "204   Quebec     G9X 3P4  Canada  47.771220 -73.334097  \n",
      "205  Ontario     N8Y 2M9  Canada  42.324933 -83.007134  \n",
      "206  Ontario         NaN  Canada  47.511624 -82.628067  \n",
      "207  Ontario     N4S 8R4  Canada  43.126528 -80.752123  \n",
      "208  Ontario     N0N 1T0  Canada  42.947960 -82.122260  \n",
      "\n",
      "[209 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "df_merged = df_stations.merge(df_coords,on='stat_ID',how='inner')\n",
    "print(df_merged)\n",
    "df_merged.to_csv('print(df_merged).csv',header=True,index=True)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ea8dab-93ac-4139-a872-bb878b276124",
   "metadata": {},
   "source": [
    "Once you are finished, from the toolbar at the top of JupyterLab/Colab, click Kernel > **Restart Kernel and Clear All Outputs...**. Once the notebook has completed rebooting, click Run > **Run All Cells**. Make sure that all your code runs properly, and produces your merged table at the end."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c27f2b6-f6aa-4628-ba14-6252924f6d9e",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92ebda3-a4e1-48a9-9f1e-a09fd74ca780",
   "metadata": {},
   "source": [
    "Fed up with being an intermediary between your supervisor's lousy data and the pesky mapping interns, you decide to take on greater challenges. You can do the mapping, AND you can find quality data for doing so. Further, you have ambitions: you want to explore more interesting data that you can analyze and do research with."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c5eddf4-c8a9-4091-87ee-7f24345ec22d",
   "metadata": {},
   "source": [
    "# Deliverables\n",
    "\n",
    "Complete the questions in this notebook and make sure all your code runs, then upload the notebook file (*.ipynb*) to the Assignment page on Moodle. If you ran this lab in Colab, you will need to export/download the notebook file in order to upload it.\n",
    "\n",
    "Optionally, you can also create another GitHub repository for this lab and push/commit this lab file to it. For the upcoming labs, no use of GitHub repos will be necessary for marks, but they will come in handy towards the end of the term for the hosting of your webmap project, so familiarising yourself with GitHub may not be the worst idea..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
